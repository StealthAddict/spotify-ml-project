{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Need to answer the questions:\n",
    "- What is the machine learning problem you are trying to solve?\n",
    "- Why does the problem matter?\n",
    "- What could the results of your predictive model be used for?\n",
    "- Why would we want to be able to predict the thing you're trying to preduct?\n",
    "- Describe the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"spotify-2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Prep\n",
    "#### 1.1 Data Cleaning\n",
    "- Describe steps taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artist_count  released_year  released_month  released_day  \\\n",
      "0             2           2023               7            14   \n",
      "1             1           2023               3            23   \n",
      "2             1           2023               6            30   \n",
      "3             1           2019               8            23   \n",
      "4             1           2023               5            18   \n",
      "\n",
      "   in_spotify_playlists  in_spotify_charts    streams  in_apple_playlists  \\\n",
      "0                   553                147  141381703                  43   \n",
      "1                  1474                 48  133716286                  48   \n",
      "2                  1397                113  140003974                  94   \n",
      "3                  7858                100  800840817                 116   \n",
      "4                  3133                 50  303236322                  84   \n",
      "\n",
      "   in_apple_charts in_deezer_playlists  ...  C#  D  D#  E  F  F#  G  G#  \\\n",
      "0              263                  45  ...   0  0   0  0  0   0  0   0   \n",
      "1              126                  58  ...   1  0   0  0  0   0  0   0   \n",
      "2              207                  91  ...   0  0   0  0  1   0  0   0   \n",
      "3              207                 125  ...   0  0   0  0  0   0  0   0   \n",
      "4              133                  87  ...   0  0   0  0  0   0  0   0   \n",
      "\n",
      "   Major  Minor  \n",
      "0      1      0  \n",
      "1      1      0  \n",
      "2      1      0  \n",
      "3      1      0  \n",
      "4      0      1  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "#considering dropping apple/deezer data, one of these?\n",
    "#take out artist names/track name\n",
    "df = data.drop(['track_name', 'artist(s)_name'], axis=1)\n",
    "\n",
    "# Fill in NaNs in the key column with C and the NaNs in in_shazam_charts with the mean\n",
    "df['key'] = df['key'].fillna(\"C\")\n",
    "df['in_shazam_charts'] = df['in_shazam_charts'].str.replace(',', '', ).astype(float)\n",
    "shazamMean = df['in_shazam_charts'].mean(skipna=True)\n",
    "df['in_shazam_charts'] = df['in_shazam_charts'].fillna(shazamMean)\n",
    "\n",
    "one_hot = pd.get_dummies(df['key'])\n",
    "df = df.drop('key',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(df['mode'])\n",
    "df = df.drop('mode',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data Exploration\n",
    "- Describe steps taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       artist_count  released_year  released_month  released_day  \\\n",
      "count    953.000000     953.000000      953.000000    953.000000   \n",
      "mean       1.556139    2018.238195        6.033578     13.930745   \n",
      "std        0.893044      11.116218        3.566435      9.201949   \n",
      "min        1.000000    1930.000000        1.000000      1.000000   \n",
      "25%        1.000000    2020.000000        3.000000      6.000000   \n",
      "50%        1.000000    2022.000000        6.000000     13.000000   \n",
      "75%        2.000000    2022.000000        9.000000     22.000000   \n",
      "max        8.000000    2023.000000       12.000000     31.000000   \n",
      "\n",
      "       in_spotify_playlists  in_spotify_charts  in_apple_playlists  \\\n",
      "count            953.000000         953.000000          953.000000   \n",
      "mean            5200.124869          12.009444           67.812172   \n",
      "std             7897.608990          19.575992           86.441493   \n",
      "min               31.000000           0.000000            0.000000   \n",
      "25%              875.000000           0.000000           13.000000   \n",
      "50%             2224.000000           3.000000           34.000000   \n",
      "75%             5542.000000          16.000000           88.000000   \n",
      "max            52898.000000         147.000000          672.000000   \n",
      "\n",
      "       in_apple_charts  in_deezer_charts         bpm  danceability_%  \\\n",
      "count       953.000000        953.000000  953.000000       953.00000   \n",
      "mean         51.908709          2.666317  122.540399        66.96957   \n",
      "std          50.630241          6.035599   28.057802        14.63061   \n",
      "min           0.000000          0.000000   65.000000        23.00000   \n",
      "25%           7.000000          0.000000  100.000000        57.00000   \n",
      "50%          38.000000          0.000000  121.000000        69.00000   \n",
      "75%          87.000000          2.000000  140.000000        78.00000   \n",
      "max         275.000000         58.000000  206.000000        96.00000   \n",
      "\n",
      "        valence_%    energy_%  acousticness_%  instrumentalness_%  liveness_%  \\\n",
      "count  953.000000  953.000000      953.000000          953.000000  953.000000   \n",
      "mean    51.431270   64.279119       27.057712            1.581322   18.213012   \n",
      "std     23.480632   16.550526       25.996077            8.409800   13.711223   \n",
      "min      4.000000    9.000000        0.000000            0.000000    3.000000   \n",
      "25%     32.000000   53.000000        6.000000            0.000000   10.000000   \n",
      "50%     51.000000   66.000000       18.000000            0.000000   12.000000   \n",
      "75%     70.000000   77.000000       43.000000            0.000000   24.000000   \n",
      "max     97.000000   97.000000       97.000000           91.000000   97.000000   \n",
      "\n",
      "       speechiness_%  \n",
      "count     953.000000  \n",
      "mean       10.131165  \n",
      "std         9.912888  \n",
      "min         2.000000  \n",
      "25%         4.000000  \n",
      "50%         6.000000  \n",
      "75%        11.000000  \n",
      "max        64.000000  \n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Feature Engineering\n",
    "- Describe steps taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Additional ML Tasks\n",
    ">  If your dataset requires very little cleaning and/or feature engineering, then the points in this area should be earned by doing something additional in another area!\n",
    ">\n",
    "> This could include more thorough/more in-depth data exploration; performing anomaly detection on the data; performing and evaluating various clustering algorithms; implementing more advance modeling techniques or algorithms (beyond the models taught in class); or other things beyond what is listed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling\n",
    "- Describe process and models tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Results\n",
    "- Describe results of final modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
